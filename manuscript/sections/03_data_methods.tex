% How Are surveys coded
% Concider using fewer categories 
% Be transparent about keywords, 
% Validation methods 

\section*{Data and Methods}
To test the hypotheses, my empirical analyses proceed in three steps. First, I investigate male and female citizens' issue priorities. This analysis draws on data from the Norwegian Citizen Panel \parencite{ivarsflaten_norwegian_2024}, comprising 123,023 observations from eighteen rounds of surveys conducted between 2013 and 2023. To assess citizens' issue priorities, I analysed coded open-ended responses to questions where panel members were asked to name the most important political issue.

Secondly, I rely on speech data covering the same ten-year period to evaluate elected representatives' issue priorities and test their correspondence with the issues prioritised by citizens. The speech data comprises 111, 477 speech observations observations collected through scraping the Norwegian \textit{Storting's} API.\footnote{Scraping relied mostly on R-packages \textit{rvest} and \textit{stortingsscrape}. \color{red}I plan to include a part in the appendix on the speech scraping} Furthermore, the data set includes meta variables at the speaker and speech levels that allow for estimating whether male and female representatives differ in their issue attention and how this varies over time. % Appendix should go here: 

% Perhaps in the appendix, then shares in the main paper more clear on what the survey data represents. 
To analyse the data, I conduct twenty separate logistic mixed-effect models with the objective of estimating the likelihood of women prioritising specific issues compared to men.\footnote{I use the glmer function from R-package \textit{lme4} \parencite{bates_lme4_2023}.} A binary dependent variable is defined for each issue, indicating whether a respondent has identified an issue within a specific category as the most important issue in a particular survey round. Each model includes controls for respondents' age, level of education, region of residence, and time-fixed effects to adjust for temporal variations. Furthermore, due to the panel structure of the data, which requires accounting for the non-independence of observations, I incorporate random intercepts at the level of the individual respondent. All models are weighted to ensure that the findings are representative of the Norwegian public. \footnote{\color{red} A figure of weight distribution will be presented in the appendix }   The specification of each logistic mixed-effect model incorporates the following structure:
\begin{equation}
\text{logit}(P(\text{issue}_{ij} = 1)) = \beta_0 + \beta_1 \times \text{gender}_i + \beta_2 \times \text{age}_i + \beta_3 \times \text{education}_i + \beta_4 \times \text{region}_i + \beta_5 \times \text{round}_j + u_j
\end{equation}

Where $P(\text{issue}_{ij} = 1)$ is the probability that individual $i$ in survey round $j$ prioritises a specific policy issue, $\text{gender}_i$ is the gender of the respondent, $\text{age}_i$, $\text{education}_i$, and $\text{region}_i$ represent the age, level of education, and region of residence of the respondent, respectively. $\text{round}_j$ represents the fixed effects for each survey round to control for time-specific variations, and $u_j$ represents the random intercept for respondent $i$, accounting for the non-independence of observations within the same individual across different survey rounds.

% Explain Keyword selection, 
\subsection*{Measuring biases in priority responsiveness}
The next step is to test $H1_{a}$, determining whether representatives display equal levels of priority responsiveness to men and women benefit from equal levels of priority responsiveness and $H1_{b}$, assessing whether representatives are more likely to prioritise issues that citizens of the same gender are more inclined to prioritise. To estimate the relationship between citizens' and representatives' priorities, I run regression models using measures of representatives' issue priorities as the dependent variable and measures of citizens' priorities as explanatory variables. 

\subsubsection*{Dependent variable}
My dependent variable comprises estimates of the proportion of parliamentary speeches during a given period that address specific issues. This estimation is carried out through topic modelling, a method within the broader framework of computational text analysis that uncovers latent topics and the words most strongly associated with them within a collection of documents \parencite[147]{grimmer_text_2022}.

Specifically, I employ Keyword-Assisted Topic Models (KeyATM) as recently developed by \textcite{eshima_keyword_2023}, which provides a robust extension of the Latent Dirichlet Allocation (LDA) method \parencite{blei_latent_2003}. KeyATM is a probabilistic model, assuming that each document, such as a single speech, may simultaneously be characterised by multiple topics. The model calculates the probability that each speech belongs to all topics, ensuring that the total probability across all topics for each speech equals 1. The overall probability estimates measure the proportion of speeches associated with different topics, also loading to a total of 1. 

Furthermore, KeyATM is semi-supervised, permitting researchers to provide a short list of specific keywords to guide the model in classifying topics. This feature enables theoretically guided analyses, which is particularly valuable for assessing the extent to which specific, pre-determined issues are addressed during speeches. Additionally, KeyATM supports the inclusion of covariates, thereby allowing researchers to characterise document-topic distribution with meta-information to study how estimated topics vary as a function of document-level covariates, for instance, over time.

I apply the KeyATM to the speech dataset which comprises all speeches delivered by representatives between 2013 and 2023. I excluded speeches by parliamentary presidents and vice presidents, as they primarily involve formalities and offer limited insights into policy issues. Additionally, I excluded speeches by appointed cabinet ministers. Speeches held by both regular and substitute representatives' are kept, as their task is to represent citizens by voicing their concerns. Furthermore, like all statistical models, the empirical performance of KeyATM is influenced by the quality of the input data, I therefore preprocessed the corpus comprising the speeches following standard preprocessing procedures \parencite[48-55]{grimmer_text_2022}.\footnote{see \cref{sec:preprocess} for a detailed description of the preprocessing} After preprocessing, the total amount of speeches to be analysed amounts to 102,415.

Since the goal is to assess how well the citizens' concerns are addressed, it is crucial that the topics identified by the model accurately reflect the political issues highlighted in the survey. Therefore, I begin by employing a knowledge-driven approach for selecting keywords to guide the keyATM. This involves compiling a list of topics and associated keywords that fit the twenty issue categories from the NCP survey data. This list is then supplemented with results from unsupervised models to enhance model performance. The final model is estimated with a total number of 20 topics $k$ with associated keywords for each topic. A detailed description of the keyword selection process can be found in \cref{sec:keyATM}, where \cref{appendix:key_list} shows the final selection of topics and associated keywords. 

Furthermore, evaluating how priorities change over time in response to shifts in public priorities requires estimating representatives issue attention during specific periods. Therefore, I employ the dynamic keyATM, an extension that allows assessing time trends for topic prevalence \parencite{eshima_keyword_2023}. By incorporating timestamps into the estimation process using a Hidden Markov Model, the dynamic KeyATM estimates the proportion of the speeches that address specific issues during defined periods.\footnote{See \textcite{chib_estimation_1998} for a detailed explanation of the Hidden Markov Model.}\textsuperscript{,}\footnote{See \textcite{eshima_keyword_2023} for a detailed explanation of the dynamic keyATM.} I incorporate eighteen distinct timestamps corresponding to the intervals between successive citizen survey rounds.\footnote{ \colour{red}I will include a model that includes only speeches held in the 90 days after a survey round was ended to ensure a similar time interval where representation can occur after each survey round. I will present a descriptive table of the number of speeches corresponding to the time stamps}This approach makes sure there is a calculated lag between the time that citizens' answers about what is important to them were collected and the speech activity. This is essential to evaluate responsiveness as it requires representatives to follow citizens' priorities. 

I estimate two main dynamic KeyAtms; one model is conducted on a subset of speeches held by female representatives and the other on a subset of speeches held by male representatives. This division allows examining of how gender influences the alignment between citizens' priorities and the content of legislative speeches. The output from these models provides data on the proportion of speeches that discuss various topics, quantifying how much attention male and female representatives pay to different issues.
The document-topic proportions, which range from 0 to 1 for each topic, are used as dependent variables in regression models estimating the relationship between male and female citizens' priorities at time $t$ on male and female representatives' issue priorities at time $t_{+1}$. The outputs from each model conducted on gender disaggregated speeches are combined and used as the dependent variable to measure representatives' overall responsiveness to male and female citizens. \footnote{evaulations of model-fit are presented in the appendix} I further present a model testing the impact of representatives’ gender on issue priorities since parties have significant control over the issues that representatives address during debates.  \color{red}The model results, presented in appendix show that.., \color{black}

% Make some choices here on which models to include 
\subsubsection*{Independent variables}
In the models I run to assess priority responsiveness, the independent variables reflect the issue priorities of citizens, both as a total to asses overall responsiveness and disaggregated by gender to estimate responsiveness to men and women separately. Instead of using the odds ratio that predicts the likelihood of women prioritising an issue relative to men, I utilise two metrics that align more closely with the measurement of representatives' priorities to allow for comparison between levels. Following \textcite{traber_social_2022}, I calculate two distinct measures of citizens priorities. One measure indicates the proportion of women (men) prioritising an issue relative to the total number of women (men) in each survey round. For example, in the variable for women's issue priorities, 'health' would be assigned a value of 0.25 if 25 per cent of all surveyed women considered 'health' to be the most important issue in a given round. 

Men and women might differ in the intensity of priorities in terms of the share of responses per issue, but they consider the same issues to be the most important in absolute terms. Considering this possibility, I provide an additional measure by identifying the ranking of issues ranging from 1 to 20. The issue with the highest share among each gender receives a value of 20, whereas the issue that the least respondents find important receives a score of 1.  This measure gives information about the issue's relative importance but not the intensity of priorities. 

Furthermore, I calculate the gender gap in priorities, both in ranking and shares, by subtracting the values of women's issue priorities in a given round from the values of men's priorities in that same round. This allows for estimating whether representatives are more responsive to one gender than the other when men and women have different issue priorities. 

% Control variables, party affiliations
% Party in government. 

\subsubsection*{Estimation of priority responsiveness}
I employ Fractional Logit models \textcite{papke_econometric_1996}, to estimate the responsiveness of representatives to the issue priorities of both men and women. Fractional Logit models are suited for analysing time-series data in which the dependent variable is a proportion or rate bounded between 0 and 1. Hence, it is suitable for my models where the dependent reflects the share of each topic distributed over speeches. 

I run eighteen separate models. The first six models use the topic proportions of all speeches during a given period as the dependent variable, whereas the subsequent uses topic proportions of speeches disaggregated by representatives' gender as the dependent variable. For each variation in the dependent variable, I run six different models. First, I estimate the relationship between topic proportion in speeches and citizens' total shares of priorities in each round. Secondly, I include men and women citizens' priority shares separately, and thirdly, the priority gap in shares (men's priorities - women's priorities. I repeat these models using issue rankings instead of shares for the independent variables. Since reverse causality is a potential bias, additional models were estimated with a lag on the dependent variable to ensure that citizens' priorities influence representatives' priorities and not the other way around. The results of the models with a lag on the dependent variable are presented in the Appendix (SOME REF) . The general model can be expressed as follows, where \(Y\) represents the proportion of speeches belonging to a topic:

% Check this: 

\begin{equation}
    \log\left(\frac{Y}{1 - Y}\right) = \beta_0 + \beta_1 \times \text{citizens' priorities} 
\end{equation}









